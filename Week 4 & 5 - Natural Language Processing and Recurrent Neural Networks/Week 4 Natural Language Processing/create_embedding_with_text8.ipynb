{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hvivs1Q691VL"
   },
   "source": [
    "\n",
    "We will create an embedding using a small text corpus, called text8. The text8 dataset is the first 108 bytes the Large Text Compression Benchmark, which\n",
    "consists of the first 109 bytes of English Wikipedia [7]. The text8 dataset is accessible from within the gensim API as an iterable of tokens, essentially a list of tokenized sentences.\n",
    "\n",
    "[GitHub](https://github.com/PacktPublishing/Deep-Learning-with-TensorFlow-2-and-Keras/blob/master/Chapter%207/create_embedding_with_text8.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OPI4fusV-Aa0"
   },
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "7n7GAbaL84ur",
    "outputId": "e2542f38-ba0a-48a6-875f-e86950dd0cf7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "info = api.info(\"text8\")\n",
    "assert(len(info) > 0)\n",
    "\n",
    "dataset = api.load(\"text8\")  # download and load text 8  dataset\n",
    "model = Word2Vec(dataset) # we create an embedding using Word2vec model for this data\n",
    "\n",
    "model.save(\"data/text8-word2vec.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DbTEQOEN-UGz"
   },
   "source": [
    "Let us now explore the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 784
    },
    "colab_type": "code",
    "id": "7jI2Bf_M89Yq",
    "outputId": "732fe443-107b-4132-8c13-b25f80afde3f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']\n",
      "# words similar to king\n",
      "0.738 queen\n",
      "0.732 prince\n",
      "0.713 emperor\n",
      "0.699 kings\n",
      "0.686 throne\n",
      "...\n",
      "# vector arithmetic with words (cosine similarity)\n",
      "# france + berlin - paris = ?\n",
      "0.796 germany\n",
      "...\n",
      "# vector arithmetic with words (Levy and Goldberg)\n",
      "# france + berlin - paris = ?\n",
      "0.929 germany\n",
      "...\n",
      "# find odd one out\n",
      "# [hindus, parsis, singapore, christians]\n",
      "singapore\n",
      "# similarity between words\n",
      "similarity(man, woman) = 0.741\n",
      "similarity(man, dog) = 0.442\n",
      "similarity(man, whale) = 0.262\n",
      "similarity(man, tree) = 0.255\n",
      "# similar by word\n",
      "0.865 malaysia\n",
      "0.827 indonesia\n",
      "0.826 uganda\n",
      "0.821 tanzania\n",
      "0.819 zimbabwe\n",
      "...\n",
      "None\n",
      "# distance between vectors\n",
      "distance(singapore, malaysia) = 0.135\n",
      "\n",
      "# output vector obtained directly, shape: (100,)\n",
      "# output vector obtained using word_vec, shape: (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n",
      "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "def print_most_similar(word_conf_pairs, k):\n",
    "    for i, (word, conf) in enumerate(word_conf_pairs):\n",
    "        print(\"{:.3f} {:s}\".format(conf, word))\n",
    "        if i >= k-1:\n",
    "            break\n",
    "    if k < len(word_conf_pairs):\n",
    "        print(\"...\")\n",
    "\n",
    "\n",
    "\n",
    "model = KeyedVectors.load(\"data/text8-word2vec.bin\")\n",
    "word_vectors = model.wv\n",
    "\n",
    "# get words in the vocabulary\n",
    "words = word_vectors.vocab.keys()\n",
    "print([x for i, x in enumerate(words) if i < 10])\n",
    "assert(\"king\" in words)\n",
    "\n",
    "\n",
    "print(\"# words similar to king\")\n",
    "print_most_similar(word_vectors.most_similar(\"king\"), 5)\n",
    "\n",
    "print(\"# vector arithmetic with words (cosine similarity)\")\n",
    "print(\"# france + berlin - paris = ?\")\n",
    "print_most_similar(word_vectors.most_similar(\n",
    "    positive=[\"france\", \"berlin\"], negative=[\"paris\"]), 1\n",
    ")\n",
    "\n",
    "print(\"# vector arithmetic with words (Levy and Goldberg)\")\n",
    "print(\"# france + berlin - paris = ?\")\n",
    "print_most_similar(word_vectors.most_similar_cosmul(\n",
    "    positive=[\"france\", \"berlin\"], negative=[\"paris\"]), 1\n",
    ")\n",
    "\n",
    "print(\"# find odd one out\")\n",
    "print(\"# [hindus, parsis, singapore, christians]\")\n",
    "print(word_vectors.doesnt_match([\"hindus\", \"parsis\", \n",
    "    \"singapore\", \"christians\"]))\n",
    "\n",
    "print(\"# similarity between words\")\n",
    "for word in [\"woman\", \"dog\", \"whale\", \"tree\"]:\n",
    "    print(\"similarity({:s}, {:s}) = {:.3f}\".format(\n",
    "        \"man\", word,\n",
    "        word_vectors.similarity(\"man\", word)\n",
    "    ))\n",
    "\n",
    "print(\"# similar by word\")\n",
    "print(print_most_similar(\n",
    "    word_vectors.similar_by_word(\"singapore\"), 5)\n",
    ")\n",
    "\n",
    "print(\"# distance between vectors\")\n",
    "print(\"distance(singapore, malaysia) = {:.3f}\".format(\n",
    "    word_vectors.distance(\"singapore\", \"malaysia\")\n",
    "))\n",
    "\n",
    "vec_song = word_vectors[\"song\"]\n",
    "print(\"\\n# output vector obtained directly, shape:\", vec_song.shape)\n",
    "\n",
    "vec_song_2 = word_vectors.word_vec(\"song\", use_norm=True)\n",
    "print(\"# output vector obtained using word_vec, shape:\", vec_song_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5s8yd58N-9Ny"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "create_embedding_with_text8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

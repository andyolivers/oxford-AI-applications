{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"mnist.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"XuqWKiLh40kT"},"source":["### INTRODUCTION - This is the most basic model built for MNIST image classification with neural networks. Neural networks are an interconnected collection of nodes called neurons or perceptrons. Every neuron takes one piece of the input data, typically one pixel of the image, and applies a simple computation in the form of an activation function to generate a result.This example is set to explain basic concepts of data loading, neural network model building, metric evaluation and prediction. It calls for numpy random seed for reproducibilty purpose. It also explains basics of data engineering techniques such as normalization, data reshape and type conversion. It is a sequential model with single layer and kernel initialized to zero(The term kernel_initializer is a term for which statistical distribution or function to use for initialising the weights). Let's dive deep into the concepts."]},{"cell_type":"code","metadata":{"id":"XxXEXLvJ40kU"},"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"81cU3DB140kX"},"source":["### np.random.seed(0) makes the random numbers predictable\n","#### >>> numpy.random.seed(0) ; numpy.random.rand(4)\n","#### array([ 0.55,  0.72,  0.6 ,  0.54])\n","#### >>> numpy.random.seed(0) ; numpy.random.rand(4)\n","#### array([ 0.55,  0.72,  0.6 ,  0.54])\n","#### With the seed reset (every time), the same set of numbers will appear every time.\n","#### If the random seed is not reset, different numbers appear with every invocation:\n","#### >>> numpy.random.rand(4)\n","#### array([ 0.42,  0.65,  0.44,  0.89])\n","#### >>> numpy.random.rand(4)\n","#### array([ 0.96,  0.38,  0.79,  0.53])\n","#### (pseudo-)random numbers work by starting with a number (the seed), multiplying it by a large number, adding an offset, then taking modulo of that sum. The resulting number is then used as the seed to generate the next \"random\" number. When you set the seed (every time), it does the same thing every time, giving you the same numbers.\n","#### If you want seemingly random numbers, do not set the seed. If you have code that uses random numbers that you want to debug, however, it can be very helpful to set the seed before each run so that the code does the same thing every time you run it.\n","#### To get the most random numbers for each run, call numpy.random.seed(). This will cause numpy to set the seed to a random number obtained from /dev/urandom or its Windows analog or, if neither of those is available, it will use the clock.\n","#### Reference - https://stackoverflow.com/questions/21494489/what-does-numpy-random-seed0-do\n"]},{"cell_type":"code","metadata":{"id":"tlpJGlgu40kY"},"source":["# for reproducibility\n","np.random.seed(1671)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"418Nni6Z40ka"},"source":["### In neural networks, one epoch means one forward pass and one backward pass of all the training examples. Example: if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to complete 1 epoch.\n","### Reference - https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network"]},{"cell_type":"code","metadata":{"id":"1RkrEBmv40kb"},"source":["EPOCHS = 200"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pzn6a0AA40kd"},"source":["### Batch size stands for the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need. Batch size defines the number of samples that will be propagated through the network.\n","#### For instance, let's say you have 1050 training samples and you want to set up a batch_size equal to 100. The algorithm takes the first 100 samples (from 1st to 100th) from the training dataset and trains the network. Next, it takes the second 100 samples (from 101st to 200th) and trains the network again. We can keep doing this procedure until we have propagated all samples through of the network. \n","#### Advantages of using a batch size < number of all samples:\n","#### •\tIt requires less memory. Since you train the network using fewer samples, the overall training procedure requires less memory. That's especially important if you are not able to fit the whole dataset in your machine's memory.\n","#### •\tTypically networks train faster with mini-batches. That's because we update the weights after each propagation. In our example we've propagated 11 batches (10 of them had 100 samples and 1 had 50 samples) and after each of them we've updated our network's parameters. \n","\n","#### Reference - https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network"]},{"cell_type":"code","metadata":{"id":"HjlLarvG40kd"},"source":["BATCH_SIZE = 128"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3oVBuG8l40kg"},"source":["### By setting verbose 0, 1 or 2 you just say how do you want to 'see' the training progress for each epoch.\n","#### verbose=0 will show you nothing (silent)\n","#### verbose=1 will show you an animated progress bar like this:\n","#### verbose=2 will just mention the number of epoch like this:\n","#### Reference - https://stackoverflow.com/questions/47902295/what-is-the-use-of-verbose-in-keras-while-validating-the-model"]},{"cell_type":"code","metadata":{"id":"-_FEy8Kl40kg"},"source":["VERBOSE = 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TZFGpi9140ki"},"source":["### It is the number of outputs"]},{"cell_type":"code","metadata":{"id":"PlQd4j9640kj"},"source":["NB_CLASSES = 10   # number of outputs = number of digits"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0dPsk_re40kl"},"source":["### Positive integer, dimensionality of the output space that will be produced."]},{"cell_type":"code","metadata":{"id":"A1g3wbTM40ko"},"source":["N_HIDDEN = 128"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PT3wci2H40kq"},"source":["### It is the amount of data reserved for checking or proving the validity of the training process."]},{"cell_type":"code","metadata":{"id":"igKCvetg40kr"},"source":["VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_C0NYiAO40kt","executionInfo":{"status":"ok","timestamp":1604641245296,"user_tz":0,"elapsed":2860,"user":{"displayName":"A J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZDwFqnFt3HwqF4Wu3Au0RSvls62YjJWudcDUj=s64","userId":"15417262701029927930"}},"outputId":"06fed82c-7b32-4bd3-d81f-af37e020f06e","colab":{"base_uri":"https://localhost:8080/"}},"source":["mnist = keras.datasets.mnist\n","(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n","print(X_train.shape[0], 'train samples')\n","print(X_test.shape[0], 'test samples')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","60000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2WvT1efI40kv"},"source":["### Here, the training and testing data is being normalized by scaling it within a range of 0 and 1 as every value lies between 0-255.\n","https://machinelearningmastery.com/how-to-manually-scale-image-pixel-data-for-deep-learning/"]},{"cell_type":"code","metadata":{"id":"aDcRj0ru40kv"},"source":["#normalize in [0,1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"orpvAR-a40kx"},"source":["### Reshape value for 28*28 matrix"]},{"cell_type":"code","metadata":{"id":"SpkmrrQH40ky"},"source":["#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n","RESHAPED = 784"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E5qw6-yl40k0"},"source":["### This is reshaping the data from one form to the other. Here X_train is 60000 rows of 28x28 values. Therefore, we reshape it to 60000 x 784. Reshaping is done because keras convolution layers work with higher dimensions.\n","\n","https://stackoverflow.com/questions/52089601/keras-dense-layers-input-is-not-flattened/52092176#52092176"]},{"cell_type":"code","metadata":{"id":"Jt8xLrYN40k0"},"source":["X_train = X_train.reshape(60000, RESHAPED)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Im2DpI940k2"},"source":["### This is reshaping the data from one form to the other. Here X_test is 10000 rows of 28x28 values. Therefore, we reshape it to 10000 x 784. Reshaping is done because keras convolution layers work with higher dimensions."]},{"cell_type":"code","metadata":{"id":"COqgevtf40k2"},"source":["X_test = X_test.reshape(10000, RESHAPED)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CH_0T7_J40k4"},"source":["### This converts the type to 32 bit float."]},{"cell_type":"code","metadata":{"id":"SYA79lKj40k5"},"source":["Y_train = Y_train.astype('float32')\n","Y_test = Y_test.astype('float32')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OtL_Ny9n40k7"},"source":["### Sequential groups a linear stack of layers into a tf.keras.Model. Sequential provides training and inference features on this model.A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n","#### A Sequential model is not appropriate when:\n","#### •\tYour model has multiple inputs or multiple outputs\n","#### •\tAny of your layers has multiple inputs or multiple outputs\n","#### •\tYou need to do layer sharing\n","#### •\tYou want non-linear topology (e.g. a residual connection, a multi-branch model)\n","#### Reference - https://keras.io/guides/sequential_model/"]},{"cell_type":"code","metadata":{"id":"6yXfyjVa40k7"},"source":["model = tf.keras.models.Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"py1arfIgihXi"},"source":["Each neuron can be initialized with specific weights via the kernel_initializer parameter. There are a few choices, the most common of which are listed as follows:\n","\n","• random_uniform: Weights are initialized to uniformly random small values in the range -0.05 to 0.05.\n","\n","• random_normal: Weights are initialized according to a Gaussian distribution, with zero mean and a small standard deviation of 0.05. For those of you who are not familiar with Gaussian distribution, think about a symmetric \"bell curve\" shape.\n","\n","• zero: All weights are initialized to zero.\n","\n","A full list is available online at https://www.tensorflow.org/api_docs/python/\n","tf/keras/initializers."]},{"cell_type":"markdown","metadata":{"id":"GLlzro4N40k-"},"source":["### The final layer is a single neuron with activation function \"softmax\", which is a generalization of the sigmoid function. A sigmoid function output is in the range (0, 1) when the input varies in the range (−∞, ∞). Similarly, a softmax \"squashes\" a K-dimensional vector of arbitrary real values into a K-dimensional vector of real values in the range (0, 1), so that they all add up to 1. In our case, it aggregates 10 answers provided by the previous layer with 10 neurons."]},{"cell_type":"code","metadata":{"id":"aPHDHCBX40k-"},"source":["model.add(keras.layers.Dense(NB_CLASSES,\n","       input_shape=(RESHAPED,), kernel_initializer='zeros',\n","       name='dense_layer', activation='softmax'))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4DuTSsQ840lA","executionInfo":{"status":"ok","timestamp":1604641251309,"user_tz":0,"elapsed":8835,"user":{"displayName":"A J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZDwFqnFt3HwqF4Wu3Au0RSvls62YjJWudcDUj=s64","userId":"15417262701029927930"}},"outputId":"31403942-7511-46aa-aa22-ebf647ac0953","colab":{"base_uri":"https://localhost:8080/"}},"source":["# summary of the model\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_layer (Dense)          (None, 10)                7850      \n","=================================================================\n","Total params: 7,850\n","Trainable params: 7,850\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7HvW87wc40lC"},"source":["### model.compile() method compiles and creates a neural network model. It takes the following parameters – \n","### There are a few choices to be made during compilation. Firstly, we need to select an optimizer, which is the specific algorithm used to update weights while we train our model. Second, we need to select an objective function, which is used by the optimizer to navigate the space of weights (frequently, objective functions are called either loss functions or cost functions. Third, we need  to evaluate the trained model.\n","### optimizer - Optimizers are algorithms or methods used to change the attributes of your neural network such as weights and learning rate in order to reduce the losses.\n","### Various optimizers - https://medium.com/@sdoshi579/optimizers-for-training-neural-network-59450d71caf6\n","### Loss - The Loss Function is one of the important components of Neural Networks. Loss is nothing but a prediction error of Neural Net. And the method to calculate the loss is called Loss Function. In simple words, the Loss is used to calculate the gradients.\n","#### Reference - https://towardsdatascience.com/understanding-different-loss-functions-for-neural-networks-dd1ed0274718\n","### Metrics - A metric is a function that is used to judge the performance of your model. Metric functions are similar to loss functions, except that the results from evaluating a metric are not used when training the model. Note that you may use any loss functions as a metric function.\n","#### Different metrics and reference - https://keras.io/api/metrics/"]},{"cell_type":"code","metadata":{"id":"057O-hOE40lC"},"source":["# compiling the model\n","model.compile(optimizer='SGD', \n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FqhGfC5I40lE","executionInfo":{"status":"ok","timestamp":1604641453815,"user_tz":0,"elapsed":211332,"user":{"displayName":"A J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZDwFqnFt3HwqF4Wu3Au0RSvls62YjJWudcDUj=s64","userId":"15417262701029927930"}},"outputId":"f0370b89-2348-4540-d538-7bab3f704d8a","colab":{"base_uri":"https://localhost:8080/"}},"source":["#training the moodel\n","model.fit(X_train, Y_train,\n","        batch_size=BATCH_SIZE, epochs=EPOCHS,\n","        verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","375/375 [==============================] - 1s 3ms/step - loss: 1.3527 - accuracy: 0.7811 - val_loss: 0.8783 - val_accuracy: 0.8418\n","Epoch 2/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.7803 - accuracy: 0.8417 - val_loss: 0.6478 - val_accuracy: 0.8642\n","Epoch 3/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.6349 - accuracy: 0.8569 - val_loss: 0.5548 - val_accuracy: 0.8754\n","Epoch 4/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.5645 - accuracy: 0.8661 - val_loss: 0.5033 - val_accuracy: 0.8812\n","Epoch 5/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.5215 - accuracy: 0.8722 - val_loss: 0.4700 - val_accuracy: 0.8867\n","Epoch 6/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4921 - accuracy: 0.8761 - val_loss: 0.4465 - val_accuracy: 0.8888\n","Epoch 7/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4702 - accuracy: 0.8800 - val_loss: 0.4291 - val_accuracy: 0.8910\n","Epoch 8/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4533 - accuracy: 0.8825 - val_loss: 0.4149 - val_accuracy: 0.8945\n","Epoch 9/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4396 - accuracy: 0.8850 - val_loss: 0.4036 - val_accuracy: 0.8966\n","Epoch 10/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4282 - accuracy: 0.8872 - val_loss: 0.3943 - val_accuracy: 0.8988\n","Epoch 11/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4187 - accuracy: 0.8893 - val_loss: 0.3864 - val_accuracy: 0.8995\n","Epoch 12/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4104 - accuracy: 0.8908 - val_loss: 0.3797 - val_accuracy: 0.9004\n","Epoch 13/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4032 - accuracy: 0.8917 - val_loss: 0.3736 - val_accuracy: 0.9027\n","Epoch 14/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3969 - accuracy: 0.8935 - val_loss: 0.3685 - val_accuracy: 0.9021\n","Epoch 15/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3912 - accuracy: 0.8944 - val_loss: 0.3637 - val_accuracy: 0.9036\n","Epoch 16/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3861 - accuracy: 0.8952 - val_loss: 0.3594 - val_accuracy: 0.9046\n","Epoch 17/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3815 - accuracy: 0.8964 - val_loss: 0.3557 - val_accuracy: 0.9047\n","Epoch 18/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3773 - accuracy: 0.8971 - val_loss: 0.3521 - val_accuracy: 0.9055\n","Epoch 19/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3734 - accuracy: 0.8979 - val_loss: 0.3492 - val_accuracy: 0.9059\n","Epoch 20/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3699 - accuracy: 0.8986 - val_loss: 0.3461 - val_accuracy: 0.9068\n","Epoch 21/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3666 - accuracy: 0.8995 - val_loss: 0.3435 - val_accuracy: 0.9076\n","Epoch 22/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3636 - accuracy: 0.9004 - val_loss: 0.3410 - val_accuracy: 0.9082\n","Epoch 23/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3607 - accuracy: 0.9008 - val_loss: 0.3386 - val_accuracy: 0.9082\n","Epoch 24/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3581 - accuracy: 0.9015 - val_loss: 0.3365 - val_accuracy: 0.9086\n","Epoch 25/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3556 - accuracy: 0.9017 - val_loss: 0.3345 - val_accuracy: 0.9099\n","Epoch 26/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3532 - accuracy: 0.9023 - val_loss: 0.3326 - val_accuracy: 0.9103\n","Epoch 27/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3510 - accuracy: 0.9028 - val_loss: 0.3309 - val_accuracy: 0.9099\n","Epoch 28/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3489 - accuracy: 0.9034 - val_loss: 0.3291 - val_accuracy: 0.9108\n","Epoch 29/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.9039 - val_loss: 0.3274 - val_accuracy: 0.9108\n","Epoch 30/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3451 - accuracy: 0.9044 - val_loss: 0.3258 - val_accuracy: 0.9121\n","Epoch 31/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3433 - accuracy: 0.9050 - val_loss: 0.3244 - val_accuracy: 0.9119\n","Epoch 32/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3416 - accuracy: 0.9056 - val_loss: 0.3230 - val_accuracy: 0.9118\n","Epoch 33/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3400 - accuracy: 0.9057 - val_loss: 0.3218 - val_accuracy: 0.9119\n","Epoch 34/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3384 - accuracy: 0.9063 - val_loss: 0.3205 - val_accuracy: 0.9127\n","Epoch 35/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3370 - accuracy: 0.9065 - val_loss: 0.3194 - val_accuracy: 0.9128\n","Epoch 36/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3355 - accuracy: 0.9070 - val_loss: 0.3182 - val_accuracy: 0.9128\n","Epoch 37/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3341 - accuracy: 0.9074 - val_loss: 0.3171 - val_accuracy: 0.9131\n","Epoch 38/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3328 - accuracy: 0.9076 - val_loss: 0.3160 - val_accuracy: 0.9137\n","Epoch 39/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3316 - accuracy: 0.9081 - val_loss: 0.3150 - val_accuracy: 0.9140\n","Epoch 40/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3303 - accuracy: 0.9081 - val_loss: 0.3142 - val_accuracy: 0.9145\n","Epoch 41/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.9086 - val_loss: 0.3130 - val_accuracy: 0.9143\n","Epoch 42/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3281 - accuracy: 0.9090 - val_loss: 0.3122 - val_accuracy: 0.9148\n","Epoch 43/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3270 - accuracy: 0.9092 - val_loss: 0.3113 - val_accuracy: 0.9149\n","Epoch 44/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3259 - accuracy: 0.9096 - val_loss: 0.3106 - val_accuracy: 0.9149\n","Epoch 45/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3249 - accuracy: 0.9100 - val_loss: 0.3098 - val_accuracy: 0.9147\n","Epoch 46/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.9101 - val_loss: 0.3091 - val_accuracy: 0.9153\n","Epoch 47/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3230 - accuracy: 0.9103 - val_loss: 0.3082 - val_accuracy: 0.9156\n","Epoch 48/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3220 - accuracy: 0.9105 - val_loss: 0.3075 - val_accuracy: 0.9157\n","Epoch 49/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3211 - accuracy: 0.9113 - val_loss: 0.3068 - val_accuracy: 0.9156\n","Epoch 50/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3202 - accuracy: 0.9112 - val_loss: 0.3062 - val_accuracy: 0.9153\n","Epoch 51/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3194 - accuracy: 0.9114 - val_loss: 0.3054 - val_accuracy: 0.9158\n","Epoch 52/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3186 - accuracy: 0.9119 - val_loss: 0.3048 - val_accuracy: 0.9158\n","Epoch 53/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3178 - accuracy: 0.9119 - val_loss: 0.3042 - val_accuracy: 0.9156\n","Epoch 54/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3170 - accuracy: 0.9122 - val_loss: 0.3036 - val_accuracy: 0.9158\n","Epoch 55/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3162 - accuracy: 0.9123 - val_loss: 0.3031 - val_accuracy: 0.9159\n","Epoch 56/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3155 - accuracy: 0.9123 - val_loss: 0.3024 - val_accuracy: 0.9157\n","Epoch 57/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3148 - accuracy: 0.9129 - val_loss: 0.3019 - val_accuracy: 0.9156\n","Epoch 58/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3141 - accuracy: 0.9130 - val_loss: 0.3013 - val_accuracy: 0.9159\n","Epoch 59/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3134 - accuracy: 0.9131 - val_loss: 0.3008 - val_accuracy: 0.9166\n","Epoch 60/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3127 - accuracy: 0.9135 - val_loss: 0.3004 - val_accuracy: 0.9161\n","Epoch 61/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3121 - accuracy: 0.9134 - val_loss: 0.2998 - val_accuracy: 0.9160\n","Epoch 62/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3115 - accuracy: 0.9137 - val_loss: 0.2994 - val_accuracy: 0.9163\n","Epoch 63/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3109 - accuracy: 0.9142 - val_loss: 0.2989 - val_accuracy: 0.9167\n","Epoch 64/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3102 - accuracy: 0.9141 - val_loss: 0.2984 - val_accuracy: 0.9168\n","Epoch 65/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3097 - accuracy: 0.9140 - val_loss: 0.2980 - val_accuracy: 0.9168\n","Epoch 66/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3091 - accuracy: 0.9147 - val_loss: 0.2975 - val_accuracy: 0.9168\n","Epoch 67/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3085 - accuracy: 0.9147 - val_loss: 0.2971 - val_accuracy: 0.9172\n","Epoch 68/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3080 - accuracy: 0.9149 - val_loss: 0.2967 - val_accuracy: 0.9172\n","Epoch 69/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3074 - accuracy: 0.9150 - val_loss: 0.2963 - val_accuracy: 0.9172\n","Epoch 70/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3069 - accuracy: 0.9152 - val_loss: 0.2960 - val_accuracy: 0.9173\n","Epoch 71/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3064 - accuracy: 0.9155 - val_loss: 0.2956 - val_accuracy: 0.9176\n","Epoch 72/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3059 - accuracy: 0.9156 - val_loss: 0.2951 - val_accuracy: 0.9177\n","Epoch 73/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3054 - accuracy: 0.9154 - val_loss: 0.2948 - val_accuracy: 0.9178\n","Epoch 74/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3049 - accuracy: 0.9157 - val_loss: 0.2944 - val_accuracy: 0.9181\n","Epoch 75/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3044 - accuracy: 0.9157 - val_loss: 0.2940 - val_accuracy: 0.9180\n","Epoch 76/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3039 - accuracy: 0.9159 - val_loss: 0.2937 - val_accuracy: 0.9179\n","Epoch 77/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3035 - accuracy: 0.9160 - val_loss: 0.2934 - val_accuracy: 0.9183\n","Epoch 78/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3030 - accuracy: 0.9160 - val_loss: 0.2930 - val_accuracy: 0.9183\n","Epoch 79/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3025 - accuracy: 0.9160 - val_loss: 0.2927 - val_accuracy: 0.9183\n","Epoch 80/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3021 - accuracy: 0.9163 - val_loss: 0.2923 - val_accuracy: 0.9183\n","Epoch 81/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3017 - accuracy: 0.9166 - val_loss: 0.2920 - val_accuracy: 0.9183\n","Epoch 82/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3013 - accuracy: 0.9165 - val_loss: 0.2918 - val_accuracy: 0.9186\n","Epoch 83/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3009 - accuracy: 0.9162 - val_loss: 0.2915 - val_accuracy: 0.9186\n","Epoch 84/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3005 - accuracy: 0.9164 - val_loss: 0.2911 - val_accuracy: 0.9189\n","Epoch 85/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3001 - accuracy: 0.9168 - val_loss: 0.2908 - val_accuracy: 0.9189\n","Epoch 86/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2997 - accuracy: 0.9168 - val_loss: 0.2906 - val_accuracy: 0.9184\n","Epoch 87/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2993 - accuracy: 0.9169 - val_loss: 0.2903 - val_accuracy: 0.9186\n","Epoch 88/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2989 - accuracy: 0.9169 - val_loss: 0.2901 - val_accuracy: 0.9191\n","Epoch 89/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2985 - accuracy: 0.9170 - val_loss: 0.2898 - val_accuracy: 0.9191\n","Epoch 90/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2981 - accuracy: 0.9174 - val_loss: 0.2895 - val_accuracy: 0.9191\n","Epoch 91/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2978 - accuracy: 0.9175 - val_loss: 0.2892 - val_accuracy: 0.9192\n","Epoch 92/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2974 - accuracy: 0.9171 - val_loss: 0.2890 - val_accuracy: 0.9192\n","Epoch 93/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2971 - accuracy: 0.9175 - val_loss: 0.2888 - val_accuracy: 0.9193\n","Epoch 94/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2968 - accuracy: 0.9181 - val_loss: 0.2885 - val_accuracy: 0.9192\n","Epoch 95/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2964 - accuracy: 0.9177 - val_loss: 0.2883 - val_accuracy: 0.9195\n","Epoch 96/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2961 - accuracy: 0.9177 - val_loss: 0.2881 - val_accuracy: 0.9197\n","Epoch 97/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2957 - accuracy: 0.9178 - val_loss: 0.2877 - val_accuracy: 0.9206\n","Epoch 98/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2954 - accuracy: 0.9181 - val_loss: 0.2876 - val_accuracy: 0.9197\n","Epoch 99/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2951 - accuracy: 0.9182 - val_loss: 0.2874 - val_accuracy: 0.9196\n","Epoch 100/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2948 - accuracy: 0.9184 - val_loss: 0.2871 - val_accuracy: 0.9202\n","Epoch 101/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2944 - accuracy: 0.9183 - val_loss: 0.2870 - val_accuracy: 0.9202\n","Epoch 102/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2941 - accuracy: 0.9181 - val_loss: 0.2866 - val_accuracy: 0.9202\n","Epoch 103/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2938 - accuracy: 0.9184 - val_loss: 0.2865 - val_accuracy: 0.9202\n","Epoch 104/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2935 - accuracy: 0.9184 - val_loss: 0.2863 - val_accuracy: 0.9201\n","Epoch 105/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2932 - accuracy: 0.9184 - val_loss: 0.2862 - val_accuracy: 0.9202\n","Epoch 106/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2930 - accuracy: 0.9185 - val_loss: 0.2858 - val_accuracy: 0.9206\n","Epoch 107/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2926 - accuracy: 0.9186 - val_loss: 0.2856 - val_accuracy: 0.9202\n","Epoch 108/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2924 - accuracy: 0.9191 - val_loss: 0.2855 - val_accuracy: 0.9201\n","Epoch 109/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2921 - accuracy: 0.9191 - val_loss: 0.2853 - val_accuracy: 0.9206\n","Epoch 110/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2918 - accuracy: 0.9189 - val_loss: 0.2851 - val_accuracy: 0.9207\n","Epoch 111/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2916 - accuracy: 0.9191 - val_loss: 0.2849 - val_accuracy: 0.9207\n","Epoch 112/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2913 - accuracy: 0.9192 - val_loss: 0.2848 - val_accuracy: 0.9205\n","Epoch 113/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2910 - accuracy: 0.9193 - val_loss: 0.2845 - val_accuracy: 0.9208\n","Epoch 114/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2908 - accuracy: 0.9193 - val_loss: 0.2844 - val_accuracy: 0.9209\n","Epoch 115/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2905 - accuracy: 0.9195 - val_loss: 0.2842 - val_accuracy: 0.9204\n","Epoch 116/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2903 - accuracy: 0.9194 - val_loss: 0.2840 - val_accuracy: 0.9206\n","Epoch 117/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2900 - accuracy: 0.9196 - val_loss: 0.2839 - val_accuracy: 0.9210\n","Epoch 118/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2898 - accuracy: 0.9196 - val_loss: 0.2836 - val_accuracy: 0.9208\n","Epoch 119/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2895 - accuracy: 0.9196 - val_loss: 0.2834 - val_accuracy: 0.9210\n","Epoch 120/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2893 - accuracy: 0.9196 - val_loss: 0.2833 - val_accuracy: 0.9209\n","Epoch 121/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2890 - accuracy: 0.9197 - val_loss: 0.2832 - val_accuracy: 0.9210\n","Epoch 122/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2888 - accuracy: 0.9197 - val_loss: 0.2830 - val_accuracy: 0.9212\n","Epoch 123/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2886 - accuracy: 0.9199 - val_loss: 0.2829 - val_accuracy: 0.9212\n","Epoch 124/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2883 - accuracy: 0.9199 - val_loss: 0.2827 - val_accuracy: 0.9215\n","Epoch 125/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2881 - accuracy: 0.9200 - val_loss: 0.2826 - val_accuracy: 0.9212\n","Epoch 126/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2879 - accuracy: 0.9200 - val_loss: 0.2824 - val_accuracy: 0.9213\n","Epoch 127/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2876 - accuracy: 0.9198 - val_loss: 0.2824 - val_accuracy: 0.9212\n","Epoch 128/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2874 - accuracy: 0.9202 - val_loss: 0.2822 - val_accuracy: 0.9209\n","Epoch 129/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2872 - accuracy: 0.9200 - val_loss: 0.2820 - val_accuracy: 0.9214\n","Epoch 130/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2870 - accuracy: 0.9201 - val_loss: 0.2818 - val_accuracy: 0.9212\n","Epoch 131/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2868 - accuracy: 0.9202 - val_loss: 0.2817 - val_accuracy: 0.9212\n","Epoch 132/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2865 - accuracy: 0.9204 - val_loss: 0.2816 - val_accuracy: 0.9212\n","Epoch 133/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2863 - accuracy: 0.9202 - val_loss: 0.2814 - val_accuracy: 0.9216\n","Epoch 134/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2861 - accuracy: 0.9204 - val_loss: 0.2812 - val_accuracy: 0.9214\n","Epoch 135/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2859 - accuracy: 0.9205 - val_loss: 0.2811 - val_accuracy: 0.9212\n","Epoch 136/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2857 - accuracy: 0.9205 - val_loss: 0.2809 - val_accuracy: 0.9216\n","Epoch 137/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2855 - accuracy: 0.9205 - val_loss: 0.2809 - val_accuracy: 0.9216\n","Epoch 138/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2853 - accuracy: 0.9205 - val_loss: 0.2808 - val_accuracy: 0.9215\n","Epoch 139/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2851 - accuracy: 0.9207 - val_loss: 0.2807 - val_accuracy: 0.9218\n","Epoch 140/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2849 - accuracy: 0.9206 - val_loss: 0.2805 - val_accuracy: 0.9219\n","Epoch 141/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2847 - accuracy: 0.9206 - val_loss: 0.2804 - val_accuracy: 0.9218\n","Epoch 142/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2845 - accuracy: 0.9208 - val_loss: 0.2803 - val_accuracy: 0.9219\n","Epoch 143/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2844 - accuracy: 0.9207 - val_loss: 0.2801 - val_accuracy: 0.9218\n","Epoch 144/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2841 - accuracy: 0.9209 - val_loss: 0.2800 - val_accuracy: 0.9220\n","Epoch 145/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2840 - accuracy: 0.9210 - val_loss: 0.2799 - val_accuracy: 0.9219\n","Epoch 146/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2838 - accuracy: 0.9208 - val_loss: 0.2798 - val_accuracy: 0.9219\n","Epoch 147/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2836 - accuracy: 0.9213 - val_loss: 0.2797 - val_accuracy: 0.9222\n","Epoch 148/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2834 - accuracy: 0.9211 - val_loss: 0.2795 - val_accuracy: 0.9218\n","Epoch 149/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2832 - accuracy: 0.9213 - val_loss: 0.2795 - val_accuracy: 0.9219\n","Epoch 150/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2831 - accuracy: 0.9209 - val_loss: 0.2793 - val_accuracy: 0.9218\n","Epoch 151/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2829 - accuracy: 0.9212 - val_loss: 0.2792 - val_accuracy: 0.9222\n","Epoch 152/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2827 - accuracy: 0.9215 - val_loss: 0.2791 - val_accuracy: 0.9219\n","Epoch 153/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2825 - accuracy: 0.9210 - val_loss: 0.2790 - val_accuracy: 0.9218\n","Epoch 154/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2823 - accuracy: 0.9213 - val_loss: 0.2788 - val_accuracy: 0.9222\n","Epoch 155/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2822 - accuracy: 0.9216 - val_loss: 0.2787 - val_accuracy: 0.9223\n","Epoch 156/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2820 - accuracy: 0.9213 - val_loss: 0.2786 - val_accuracy: 0.9222\n","Epoch 157/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2818 - accuracy: 0.9213 - val_loss: 0.2786 - val_accuracy: 0.9223\n","Epoch 158/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2817 - accuracy: 0.9215 - val_loss: 0.2785 - val_accuracy: 0.9224\n","Epoch 159/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2815 - accuracy: 0.9215 - val_loss: 0.2784 - val_accuracy: 0.9222\n","Epoch 160/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2814 - accuracy: 0.9215 - val_loss: 0.2783 - val_accuracy: 0.9225\n","Epoch 161/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2812 - accuracy: 0.9218 - val_loss: 0.2781 - val_accuracy: 0.9228\n","Epoch 162/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2810 - accuracy: 0.9218 - val_loss: 0.2781 - val_accuracy: 0.9226\n","Epoch 163/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2809 - accuracy: 0.9218 - val_loss: 0.2779 - val_accuracy: 0.9227\n","Epoch 164/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2807 - accuracy: 0.9217 - val_loss: 0.2779 - val_accuracy: 0.9222\n","Epoch 165/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2806 - accuracy: 0.9217 - val_loss: 0.2778 - val_accuracy: 0.9225\n","Epoch 166/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2804 - accuracy: 0.9219 - val_loss: 0.2776 - val_accuracy: 0.9229\n","Epoch 167/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2803 - accuracy: 0.9218 - val_loss: 0.2775 - val_accuracy: 0.9230\n","Epoch 168/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2801 - accuracy: 0.9221 - val_loss: 0.2775 - val_accuracy: 0.9227\n","Epoch 169/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2799 - accuracy: 0.9218 - val_loss: 0.2774 - val_accuracy: 0.9227\n","Epoch 170/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2798 - accuracy: 0.9221 - val_loss: 0.2773 - val_accuracy: 0.9229\n","Epoch 171/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2796 - accuracy: 0.9221 - val_loss: 0.2772 - val_accuracy: 0.9230\n","Epoch 172/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2795 - accuracy: 0.9221 - val_loss: 0.2771 - val_accuracy: 0.9228\n","Epoch 173/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2794 - accuracy: 0.9221 - val_loss: 0.2770 - val_accuracy: 0.9226\n","Epoch 174/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2792 - accuracy: 0.9219 - val_loss: 0.2769 - val_accuracy: 0.9232\n","Epoch 175/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2790 - accuracy: 0.9224 - val_loss: 0.2768 - val_accuracy: 0.9227\n","Epoch 176/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2789 - accuracy: 0.9225 - val_loss: 0.2768 - val_accuracy: 0.9228\n","Epoch 177/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2788 - accuracy: 0.9222 - val_loss: 0.2767 - val_accuracy: 0.9225\n","Epoch 178/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2786 - accuracy: 0.9224 - val_loss: 0.2766 - val_accuracy: 0.9231\n","Epoch 179/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2785 - accuracy: 0.9224 - val_loss: 0.2765 - val_accuracy: 0.9232\n","Epoch 180/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2783 - accuracy: 0.9224 - val_loss: 0.2765 - val_accuracy: 0.9228\n","Epoch 181/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2782 - accuracy: 0.9224 - val_loss: 0.2763 - val_accuracy: 0.9228\n","Epoch 182/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2781 - accuracy: 0.9224 - val_loss: 0.2763 - val_accuracy: 0.9228\n","Epoch 183/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2779 - accuracy: 0.9224 - val_loss: 0.2762 - val_accuracy: 0.9227\n","Epoch 184/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2778 - accuracy: 0.9225 - val_loss: 0.2761 - val_accuracy: 0.9235\n","Epoch 185/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2777 - accuracy: 0.9225 - val_loss: 0.2760 - val_accuracy: 0.9230\n","Epoch 186/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2775 - accuracy: 0.9229 - val_loss: 0.2761 - val_accuracy: 0.9222\n","Epoch 187/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2774 - accuracy: 0.9225 - val_loss: 0.2759 - val_accuracy: 0.9230\n","Epoch 188/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2773 - accuracy: 0.9227 - val_loss: 0.2758 - val_accuracy: 0.9232\n","Epoch 189/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2772 - accuracy: 0.9225 - val_loss: 0.2757 - val_accuracy: 0.9233\n","Epoch 190/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2770 - accuracy: 0.9229 - val_loss: 0.2756 - val_accuracy: 0.9239\n","Epoch 191/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2769 - accuracy: 0.9228 - val_loss: 0.2755 - val_accuracy: 0.9232\n","Epoch 192/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2768 - accuracy: 0.9227 - val_loss: 0.2755 - val_accuracy: 0.9228\n","Epoch 193/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2767 - accuracy: 0.9229 - val_loss: 0.2755 - val_accuracy: 0.9231\n","Epoch 194/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2765 - accuracy: 0.9226 - val_loss: 0.2753 - val_accuracy: 0.9237\n","Epoch 195/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2764 - accuracy: 0.9228 - val_loss: 0.2753 - val_accuracy: 0.9237\n","Epoch 196/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2763 - accuracy: 0.9229 - val_loss: 0.2752 - val_accuracy: 0.9237\n","Epoch 197/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2762 - accuracy: 0.9229 - val_loss: 0.2752 - val_accuracy: 0.9233\n","Epoch 198/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2760 - accuracy: 0.9231 - val_loss: 0.2751 - val_accuracy: 0.9233\n","Epoch 199/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2759 - accuracy: 0.9231 - val_loss: 0.2750 - val_accuracy: 0.9238\n","Epoch 200/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2758 - accuracy: 0.9229 - val_loss: 0.2749 - val_accuracy: 0.9237\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fc2303a0518>"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"NkgVzuz040lG","executionInfo":{"status":"ok","timestamp":1604641454476,"user_tz":0,"elapsed":211988,"user":{"displayName":"A J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZDwFqnFt3HwqF4Wu3Au0RSvls62YjJWudcDUj=s64","userId":"15417262701029927930"}},"outputId":"cb7bbf48-aa34-469f-9818-eab9e12ee329","colab":{"base_uri":"https://localhost:8080/"}},"source":["#evalute the model\n","test_loss, test_acc = model.evaluate(X_test, Y_test)\n","print('Test accuracy:', test_acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["313/313 [==============================] - 1s 2ms/step - loss: 0.2770 - accuracy: 0.9212\n","Test accuracy: 0.9211999773979187\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RsgJd-XP40lI"},"source":["# making prediction\n","predictions = model.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rh6l2BKwpBoB"},"source":["**Observations**\n","\n","We have acheived the training accuracy of 92.9,validation of 9237 and test accuracy of 92.1%"]}]}
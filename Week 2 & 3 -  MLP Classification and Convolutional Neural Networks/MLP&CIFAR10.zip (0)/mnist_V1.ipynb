{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"mnist_V1.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"7pU1FAyQFudW"},"source":["### INTRODUCTION - This is an extension of previous basic model built for MNIST image classification with neural networks. This also explains the basic concepts of data loading, neural network model building, metric evaluation and prediction. It is a sequential model with single layer and differs at kernel initialization which is default here. It also differs in compilation phase where loss is changed from sparse_categorical_crossentropy to categorical_crossentropy."]},{"cell_type":"code","metadata":{"id":"1iNY8wAaFudY"},"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QhKX4cfzFudh"},"source":["### In neural networks, one epoch means one forward pass and one backward pass of all the training examples. Example: if you have 1000 training examples, and your batch size is 500, then it will take 2 iterations to complete 1 epoch.\n","### Reference - https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network"]},{"cell_type":"code","metadata":{"id":"SfNdxNsPFudj"},"source":["EPOCHS = 200"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eeZw1cFjFudq"},"source":["### Batch size stands for the number of training examples in one forward/backward pass. The higher the batch size, the more memory space you'll need. Batch size defines the number of samples that will be propagated through the network.\n","#### For instance, let's say you have 1050 training samples and you want to set up a batch_size equal to 100. The algorithm takes the first 100 samples (from 1st to 100th) from the training dataset and trains the network. Next, it takes the second 100 samples (from 101st to 200th) and trains the network again. We can keep doing this procedure until we have propagated all samples through of the network. \n","#### Advantages of using a batch size < number of all samples:\n","#### •\tIt requires less memory. Since you train the network using fewer samples, the overall training procedure requires less memory. That's especially important if you are not able to fit the whole dataset in your machine's memory.\n","#### •\tTypically networks train faster with mini-batches. That's because we update the weights after each propagation. In our example we've propagated 11 batches (10 of them had 100 samples and 1 had 50 samples) and after each of them we've updated our network's parameters. \n","\n","#### Reference - https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network"]},{"cell_type":"code","metadata":{"id":"iUi0GvVVFuds"},"source":["BATCH_SIZE = 128"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uXsQ9UfmFudz"},"source":["### By setting verbose 0, 1 or 2 you just say how do you want to 'see' the training progress for each epoch.\n","#### verbose=0 will show you nothing (silent)\n","#### verbose=1 will show you an animated progress bar like this:\n","#### verbose=2 will just mention the number of epoch like this:\n","#### Reference - https://stackoverflow.com/questions/47902295/what-is-the-use-of-verbose-in-keras-while-validating-the-model"]},{"cell_type":"code","metadata":{"id":"9dxS7AL7Fud0"},"source":["VERBOSE = 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_LxolK7QFud8"},"source":["### It is the number of outputs"]},{"cell_type":"code","metadata":{"id":"HTBjAb3RFud9"},"source":["NB_CLASSES = 10   # number of outputs = number of digits"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uoPMh6HtFueF"},"source":["### Positive integer, dimensionality of the output space that will be produced."]},{"cell_type":"code","metadata":{"id":"cxaghkeNFueG"},"source":["N_HIDDEN = 128"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5rOAu_RzFueP"},"source":["### It is the amount of data reserved for checking or proving the validity of the training process."]},{"cell_type":"code","metadata":{"id":"1awgTkg7FueQ"},"source":["VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0vdJtDBuFueY"},"source":["### Loading MNIST dataset\n","### The split between train and test is 60,000, and 10,000 respectly \n","### One-hot is automatically applied"]},{"cell_type":"code","metadata":{"id":"9Vn_bzRIFueZ","executionInfo":{"status":"ok","timestamp":1604641841495,"user_tz":0,"elapsed":3227,"user":{"displayName":"A J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZDwFqnFt3HwqF4Wu3Au0RSvls62YjJWudcDUj=s64","userId":"15417262701029927930"}},"outputId":"9868a31a-eba1-4a9a-e9da-d08dd62a95c1","colab":{"base_uri":"https://localhost:8080/"}},"source":["mnist = keras.datasets.mnist\n","(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-D3OAC3EFueg"},"source":["### Reshape value for 28*28 matrix\n","### X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784"]},{"cell_type":"code","metadata":{"id":"ysazT-R8Fueh"},"source":["RESHAPED = 784"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"To-BoKfiFueo"},"source":["### This is reshaping the data from one form to the other. Here X_train is 60000 rows of 28x28 values and Therefore, we reshape it to 60000 x 784. Also, X_test is 10000 rows of 28x28 values and Therefore, we reshape it to 10000 x 784. Reshaping is done because keras convolution layers work with higher dimensions."]},{"cell_type":"code","metadata":{"id":"jUKLJNwkFuep"},"source":["X_train = X_train.reshape(60000, RESHAPED)\n","X_test = X_test.reshape(10000, RESHAPED)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IRDMWwREFuew"},"source":["### This converts the type to 32 bit float."]},{"cell_type":"code","metadata":{"id":"X9smZgw-Fuex"},"source":["X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cvXOPo8LFue5"},"source":["### Here, the training and testing data is being normalized by scaling it within a range of 0 and 1 as every value lies between 0-255."]},{"cell_type":"code","metadata":{"id":"UWcIof8AFue6","executionInfo":{"status":"ok","timestamp":1604641841507,"user_tz":0,"elapsed":3216,"user":{"displayName":"A J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZDwFqnFt3HwqF4Wu3Au0RSvls62YjJWudcDUj=s64","userId":"15417262701029927930"}},"outputId":"b99c8533-c574-4a58-90e2-70541d61965b","colab":{"base_uri":"https://localhost:8080/"}},"source":["#normalize in [0,1]\n","X_train /= 255\n","X_test /= 255\n","print(X_train.shape[0], 'train samples')\n","print(X_test.shape[0], 'test samples')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["60000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cA-Hsl2knXtC"},"source":["One-hot encoding (OHE)\n","\n","We are going to use OHE as a simple tool to encode information used inside neural networks. In many applications it is convenient to transform categorical (non- numerical) features into numerical variables. For instance, the categorical feature \"digit\" with value d in [0 – 9] can be encoded into a binary vector with 10 positions, which always has 0 value except the d - th position where a 1 is present.\n","\n","For example, the digit 3 can be encoded as [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]. This type of representation is called One-hot encoding, or sometimes simply one-hot, and is very common in data mining when the learning algorithm is specialized in dealing with numerical functions."]},{"cell_type":"code","metadata":{"id":"4sP2neVLFufB"},"source":["#one-hot\n","Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n","Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8q11VcocFufK"},"source":["### Sequential groups a linear stack of layers into a tf.keras.Model. Sequential provides training and inference features on this model.A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n","#### A Sequential model is not appropriate when:\n","#### •\tYour model has multiple inputs or multiple outputs\n","#### •\tAny of your layers has multiple inputs or multiple outputs\n","#### •\tYou need to do layer sharing\n","#### •\tYou want non-linear topology (e.g. a residual connection, a multi-branch model)\n","#### Reference - https://keras.io/guides/sequential_model/"]},{"cell_type":"code","metadata":{"id":"bmAtAj0zFufL"},"source":["#build the model\n","model = tf.keras.models.Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x_t0NHY1FufR"},"source":["### The final layer is a single neuron with activation function \"softmax\", which is a generalization of the sigmoid function. A sigmoid function output is in the range (0, 1) when the input varies in the range (−∞, ∞). Similarly, a softmax \"squashes\" a K-dimensional vector of arbitrary real values into a K-dimensional vector of real values in the range (0, 1), so that they all add up to 1. In our case, it aggregates 10 answers provided by the previous layer with 10 neurons."]},{"cell_type":"code","metadata":{"id":"juJH_2wIFufS"},"source":["model.add(keras.layers.Dense(NB_CLASSES,\n","   input_shape=(RESHAPED,),\n","   name='dense_layer', \n","   activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G-nBetI2Fufm","executionInfo":{"status":"ok","timestamp":1604641847768,"user_tz":0,"elapsed":9457,"user":{"displayName":"A J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZDwFqnFt3HwqF4Wu3Au0RSvls62YjJWudcDUj=s64","userId":"15417262701029927930"}},"outputId":"62371293-19ef-4294-f3a4-ab3d54a0f05c","colab":{"base_uri":"https://localhost:8080/"}},"source":["# summary of the model\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_layer (Dense)          (None, 10)                7850      \n","=================================================================\n","Total params: 7,850\n","Trainable params: 7,850\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cNVPCzYmFuft"},"source":["### model.compile() method compiles and creates a neural network model. It takes the following parameters – \n","### There are a few choices to be made during compilation. Firstly, we need to select an optimizer, which is the specific algorithm used to update weights while we train our model. Second, we need to select an objective function, which is used by the optimizer to navigate the space of weights (frequently, objective functions are called either loss functions or cost functions. Third, we need  to evaluate the trained model.\n","### optimizer - Optimizers are algorithms or methods used to change the attributes of your neural network such as weights and learning rate in order to reduce the losses.\n","### Various optimizers - https://medium.com/@sdoshi579/optimizers-for-training-neural-network-59450d71caf6\n","### Loss - The Loss Function is one of the important components of Neural Networks. Loss is nothing but a prediction error of Neural Net. And the method to calculate the loss is called Loss Function. In simple words, the Loss is used to calculate the gradients.\n","#### Reference - https://towardsdatascience.com/understanding-different-loss-functions-for-neural-networks-dd1ed0274718\n","### Metrics - A metric is a function that is used to judge the performance of your model. Metric functions are similar to loss functions, except that the results from evaluating a metric are not used when training the model. Note that you may use any loss functions as a metric function.\n","#### Different metrics and reference - https://keras.io/api/metrics/"]},{"cell_type":"code","metadata":{"id":"56jUr_q1Fufu"},"source":["# compiling the model\n","model.compile(optimizer='SGD', \n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lWZtDoFgFuf0","executionInfo":{"status":"ok","timestamp":1604642076807,"user_tz":0,"elapsed":238484,"user":{"displayName":"A J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZDwFqnFt3HwqF4Wu3Au0RSvls62YjJWudcDUj=s64","userId":"15417262701029927930"}},"outputId":"afe8f4b8-dab3-4b7c-eb49-bfa364519b67","colab":{"base_uri":"https://localhost:8080/"}},"source":["#training the model\n","model.fit(X_train, Y_train,\n","        batch_size=BATCH_SIZE, epochs=EPOCHS,\n","        verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","375/375 [==============================] - 1s 3ms/step - loss: 1.3646 - accuracy: 0.6695 - val_loss: 0.8819 - val_accuracy: 0.8295\n","Epoch 2/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.7838 - accuracy: 0.8304 - val_loss: 0.6484 - val_accuracy: 0.8627\n","Epoch 3/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.6364 - accuracy: 0.8522 - val_loss: 0.5548 - val_accuracy: 0.8754\n","Epoch 4/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.5653 - accuracy: 0.8634 - val_loss: 0.5032 - val_accuracy: 0.8817\n","Epoch 5/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.5221 - accuracy: 0.8704 - val_loss: 0.4700 - val_accuracy: 0.8845\n","Epoch 6/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4925 - accuracy: 0.8750 - val_loss: 0.4462 - val_accuracy: 0.8894\n","Epoch 7/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4706 - accuracy: 0.8788 - val_loss: 0.4284 - val_accuracy: 0.8923\n","Epoch 8/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4536 - accuracy: 0.8819 - val_loss: 0.4144 - val_accuracy: 0.8955\n","Epoch 9/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4399 - accuracy: 0.8844 - val_loss: 0.4033 - val_accuracy: 0.8975\n","Epoch 10/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4286 - accuracy: 0.8857 - val_loss: 0.3938 - val_accuracy: 0.8989\n","Epoch 11/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4190 - accuracy: 0.8881 - val_loss: 0.3860 - val_accuracy: 0.9005\n","Epoch 12/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4109 - accuracy: 0.8901 - val_loss: 0.3792 - val_accuracy: 0.9011\n","Epoch 13/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4036 - accuracy: 0.8913 - val_loss: 0.3734 - val_accuracy: 0.9027\n","Epoch 14/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3973 - accuracy: 0.8925 - val_loss: 0.3681 - val_accuracy: 0.9043\n","Epoch 15/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3917 - accuracy: 0.8934 - val_loss: 0.3635 - val_accuracy: 0.9046\n","Epoch 16/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3866 - accuracy: 0.8950 - val_loss: 0.3595 - val_accuracy: 0.9040\n","Epoch 17/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3820 - accuracy: 0.8955 - val_loss: 0.3556 - val_accuracy: 0.9050\n","Epoch 18/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3778 - accuracy: 0.8964 - val_loss: 0.3521 - val_accuracy: 0.9052\n","Epoch 19/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3740 - accuracy: 0.8975 - val_loss: 0.3490 - val_accuracy: 0.9053\n","Epoch 20/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3705 - accuracy: 0.8981 - val_loss: 0.3460 - val_accuracy: 0.9063\n","Epoch 21/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3672 - accuracy: 0.8989 - val_loss: 0.3433 - val_accuracy: 0.9066\n","Epoch 22/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3642 - accuracy: 0.8994 - val_loss: 0.3408 - val_accuracy: 0.9070\n","Epoch 23/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3613 - accuracy: 0.9006 - val_loss: 0.3386 - val_accuracy: 0.9078\n","Epoch 24/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3587 - accuracy: 0.9010 - val_loss: 0.3365 - val_accuracy: 0.9085\n","Epoch 25/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3562 - accuracy: 0.9019 - val_loss: 0.3345 - val_accuracy: 0.9089\n","Epoch 26/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3539 - accuracy: 0.9019 - val_loss: 0.3325 - val_accuracy: 0.9095\n","Epoch 27/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3517 - accuracy: 0.9031 - val_loss: 0.3307 - val_accuracy: 0.9100\n","Epoch 28/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3496 - accuracy: 0.9032 - val_loss: 0.3290 - val_accuracy: 0.9104\n","Epoch 29/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3476 - accuracy: 0.9037 - val_loss: 0.3274 - val_accuracy: 0.9107\n","Epoch 30/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3457 - accuracy: 0.9040 - val_loss: 0.3260 - val_accuracy: 0.9109\n","Epoch 31/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3440 - accuracy: 0.9043 - val_loss: 0.3245 - val_accuracy: 0.9118\n","Epoch 32/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3423 - accuracy: 0.9050 - val_loss: 0.3231 - val_accuracy: 0.9117\n","Epoch 33/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3406 - accuracy: 0.9054 - val_loss: 0.3219 - val_accuracy: 0.9118\n","Epoch 34/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3391 - accuracy: 0.9056 - val_loss: 0.3207 - val_accuracy: 0.9124\n","Epoch 35/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3376 - accuracy: 0.9062 - val_loss: 0.3195 - val_accuracy: 0.9133\n","Epoch 36/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3362 - accuracy: 0.9065 - val_loss: 0.3183 - val_accuracy: 0.9133\n","Epoch 37/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3348 - accuracy: 0.9066 - val_loss: 0.3172 - val_accuracy: 0.9130\n","Epoch 38/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3335 - accuracy: 0.9070 - val_loss: 0.3162 - val_accuracy: 0.9132\n","Epoch 39/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3323 - accuracy: 0.9072 - val_loss: 0.3153 - val_accuracy: 0.9138\n","Epoch 40/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.9075 - val_loss: 0.3142 - val_accuracy: 0.9142\n","Epoch 41/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3299 - accuracy: 0.9077 - val_loss: 0.3134 - val_accuracy: 0.9145\n","Epoch 42/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3288 - accuracy: 0.9082 - val_loss: 0.3125 - val_accuracy: 0.9151\n","Epoch 43/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3277 - accuracy: 0.9086 - val_loss: 0.3115 - val_accuracy: 0.9142\n","Epoch 44/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3266 - accuracy: 0.9086 - val_loss: 0.3108 - val_accuracy: 0.9146\n","Epoch 45/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3256 - accuracy: 0.9092 - val_loss: 0.3100 - val_accuracy: 0.9153\n","Epoch 46/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3246 - accuracy: 0.9091 - val_loss: 0.3092 - val_accuracy: 0.9151\n","Epoch 47/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3237 - accuracy: 0.9092 - val_loss: 0.3085 - val_accuracy: 0.9154\n","Epoch 48/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3227 - accuracy: 0.9099 - val_loss: 0.3078 - val_accuracy: 0.9153\n","Epoch 49/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3218 - accuracy: 0.9107 - val_loss: 0.3072 - val_accuracy: 0.9158\n","Epoch 50/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3210 - accuracy: 0.9104 - val_loss: 0.3064 - val_accuracy: 0.9158\n","Epoch 51/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3201 - accuracy: 0.9108 - val_loss: 0.3057 - val_accuracy: 0.9157\n","Epoch 52/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3193 - accuracy: 0.9111 - val_loss: 0.3050 - val_accuracy: 0.9159\n","Epoch 53/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3185 - accuracy: 0.9114 - val_loss: 0.3045 - val_accuracy: 0.9157\n","Epoch 54/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3177 - accuracy: 0.9117 - val_loss: 0.3039 - val_accuracy: 0.9162\n","Epoch 55/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3169 - accuracy: 0.9117 - val_loss: 0.3034 - val_accuracy: 0.9158\n","Epoch 56/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3162 - accuracy: 0.9118 - val_loss: 0.3027 - val_accuracy: 0.9162\n","Epoch 57/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3155 - accuracy: 0.9120 - val_loss: 0.3021 - val_accuracy: 0.9162\n","Epoch 58/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3148 - accuracy: 0.9125 - val_loss: 0.3017 - val_accuracy: 0.9163\n","Epoch 59/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3141 - accuracy: 0.9126 - val_loss: 0.3011 - val_accuracy: 0.9164\n","Epoch 60/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3135 - accuracy: 0.9129 - val_loss: 0.3006 - val_accuracy: 0.9165\n","Epoch 61/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3128 - accuracy: 0.9131 - val_loss: 0.3002 - val_accuracy: 0.9163\n","Epoch 62/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3122 - accuracy: 0.9132 - val_loss: 0.2996 - val_accuracy: 0.9168\n","Epoch 63/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3116 - accuracy: 0.9137 - val_loss: 0.2991 - val_accuracy: 0.9164\n","Epoch 64/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3109 - accuracy: 0.9136 - val_loss: 0.2988 - val_accuracy: 0.9172\n","Epoch 65/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3103 - accuracy: 0.9136 - val_loss: 0.2984 - val_accuracy: 0.9169\n","Epoch 66/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3098 - accuracy: 0.9142 - val_loss: 0.2979 - val_accuracy: 0.9169\n","Epoch 67/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3092 - accuracy: 0.9144 - val_loss: 0.2974 - val_accuracy: 0.9174\n","Epoch 68/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3087 - accuracy: 0.9143 - val_loss: 0.2969 - val_accuracy: 0.9177\n","Epoch 69/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3081 - accuracy: 0.9146 - val_loss: 0.2966 - val_accuracy: 0.9175\n","Epoch 70/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3076 - accuracy: 0.9148 - val_loss: 0.2961 - val_accuracy: 0.9178\n","Epoch 71/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3071 - accuracy: 0.9146 - val_loss: 0.2958 - val_accuracy: 0.9178\n","Epoch 72/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3066 - accuracy: 0.9149 - val_loss: 0.2954 - val_accuracy: 0.9177\n","Epoch 73/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3061 - accuracy: 0.9151 - val_loss: 0.2950 - val_accuracy: 0.9178\n","Epoch 74/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3056 - accuracy: 0.9154 - val_loss: 0.2947 - val_accuracy: 0.9178\n","Epoch 75/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3051 - accuracy: 0.9154 - val_loss: 0.2944 - val_accuracy: 0.9182\n","Epoch 76/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3046 - accuracy: 0.9154 - val_loss: 0.2940 - val_accuracy: 0.9179\n","Epoch 77/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3042 - accuracy: 0.9156 - val_loss: 0.2937 - val_accuracy: 0.9180\n","Epoch 78/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3037 - accuracy: 0.9156 - val_loss: 0.2933 - val_accuracy: 0.9183\n","Epoch 79/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3032 - accuracy: 0.9159 - val_loss: 0.2929 - val_accuracy: 0.9186\n","Epoch 80/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3028 - accuracy: 0.9162 - val_loss: 0.2927 - val_accuracy: 0.9185\n","Epoch 81/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3024 - accuracy: 0.9158 - val_loss: 0.2923 - val_accuracy: 0.9191\n","Epoch 82/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3020 - accuracy: 0.9163 - val_loss: 0.2920 - val_accuracy: 0.9187\n","Epoch 83/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3015 - accuracy: 0.9161 - val_loss: 0.2917 - val_accuracy: 0.9187\n","Epoch 84/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3011 - accuracy: 0.9163 - val_loss: 0.2915 - val_accuracy: 0.9190\n","Epoch 85/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3007 - accuracy: 0.9165 - val_loss: 0.2912 - val_accuracy: 0.9185\n","Epoch 86/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3003 - accuracy: 0.9167 - val_loss: 0.2909 - val_accuracy: 0.9188\n","Epoch 87/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2999 - accuracy: 0.9169 - val_loss: 0.2906 - val_accuracy: 0.9187\n","Epoch 88/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2996 - accuracy: 0.9169 - val_loss: 0.2904 - val_accuracy: 0.9187\n","Epoch 89/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2992 - accuracy: 0.9168 - val_loss: 0.2901 - val_accuracy: 0.9194\n","Epoch 90/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2988 - accuracy: 0.9170 - val_loss: 0.2898 - val_accuracy: 0.9194\n","Epoch 91/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2985 - accuracy: 0.9173 - val_loss: 0.2896 - val_accuracy: 0.9193\n","Epoch 92/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2981 - accuracy: 0.9170 - val_loss: 0.2892 - val_accuracy: 0.9193\n","Epoch 93/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2977 - accuracy: 0.9174 - val_loss: 0.2890 - val_accuracy: 0.9197\n","Epoch 94/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2973 - accuracy: 0.9175 - val_loss: 0.2889 - val_accuracy: 0.9194\n","Epoch 95/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2970 - accuracy: 0.9174 - val_loss: 0.2886 - val_accuracy: 0.9195\n","Epoch 96/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2967 - accuracy: 0.9177 - val_loss: 0.2883 - val_accuracy: 0.9200\n","Epoch 97/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2964 - accuracy: 0.9178 - val_loss: 0.2880 - val_accuracy: 0.9199\n","Epoch 98/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2960 - accuracy: 0.9178 - val_loss: 0.2879 - val_accuracy: 0.9192\n","Epoch 99/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2957 - accuracy: 0.9179 - val_loss: 0.2876 - val_accuracy: 0.9199\n","Epoch 100/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2954 - accuracy: 0.9179 - val_loss: 0.2873 - val_accuracy: 0.9201\n","Epoch 101/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2951 - accuracy: 0.9180 - val_loss: 0.2871 - val_accuracy: 0.9202\n","Epoch 102/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2948 - accuracy: 0.9179 - val_loss: 0.2868 - val_accuracy: 0.9201\n","Epoch 103/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2945 - accuracy: 0.9180 - val_loss: 0.2867 - val_accuracy: 0.9204\n","Epoch 104/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2942 - accuracy: 0.9182 - val_loss: 0.2864 - val_accuracy: 0.9205\n","Epoch 105/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2939 - accuracy: 0.9184 - val_loss: 0.2863 - val_accuracy: 0.9206\n","Epoch 106/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2936 - accuracy: 0.9182 - val_loss: 0.2861 - val_accuracy: 0.9204\n","Epoch 107/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2933 - accuracy: 0.9182 - val_loss: 0.2860 - val_accuracy: 0.9201\n","Epoch 108/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2930 - accuracy: 0.9185 - val_loss: 0.2857 - val_accuracy: 0.9204\n","Epoch 109/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2927 - accuracy: 0.9186 - val_loss: 0.2855 - val_accuracy: 0.9204\n","Epoch 110/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2925 - accuracy: 0.9186 - val_loss: 0.2853 - val_accuracy: 0.9203\n","Epoch 111/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2922 - accuracy: 0.9187 - val_loss: 0.2851 - val_accuracy: 0.9202\n","Epoch 112/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2919 - accuracy: 0.9190 - val_loss: 0.2851 - val_accuracy: 0.9201\n","Epoch 113/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2916 - accuracy: 0.9186 - val_loss: 0.2847 - val_accuracy: 0.9210\n","Epoch 114/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2914 - accuracy: 0.9187 - val_loss: 0.2846 - val_accuracy: 0.9204\n","Epoch 115/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2911 - accuracy: 0.9190 - val_loss: 0.2844 - val_accuracy: 0.9208\n","Epoch 116/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2909 - accuracy: 0.9190 - val_loss: 0.2842 - val_accuracy: 0.9207\n","Epoch 117/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2906 - accuracy: 0.9191 - val_loss: 0.2841 - val_accuracy: 0.9207\n","Epoch 118/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2904 - accuracy: 0.9190 - val_loss: 0.2839 - val_accuracy: 0.9209\n","Epoch 119/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2901 - accuracy: 0.9192 - val_loss: 0.2837 - val_accuracy: 0.9210\n","Epoch 120/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2899 - accuracy: 0.9190 - val_loss: 0.2835 - val_accuracy: 0.9211\n","Epoch 121/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2896 - accuracy: 0.9193 - val_loss: 0.2834 - val_accuracy: 0.9208\n","Epoch 122/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2894 - accuracy: 0.9192 - val_loss: 0.2832 - val_accuracy: 0.9213\n","Epoch 123/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2891 - accuracy: 0.9194 - val_loss: 0.2831 - val_accuracy: 0.9207\n","Epoch 124/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2889 - accuracy: 0.9196 - val_loss: 0.2829 - val_accuracy: 0.9214\n","Epoch 125/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2887 - accuracy: 0.9195 - val_loss: 0.2827 - val_accuracy: 0.9208\n","Epoch 126/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2884 - accuracy: 0.9193 - val_loss: 0.2826 - val_accuracy: 0.9212\n","Epoch 127/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2882 - accuracy: 0.9197 - val_loss: 0.2825 - val_accuracy: 0.9210\n","Epoch 128/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2880 - accuracy: 0.9194 - val_loss: 0.2823 - val_accuracy: 0.9212\n","Epoch 129/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2878 - accuracy: 0.9195 - val_loss: 0.2822 - val_accuracy: 0.9214\n","Epoch 130/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2875 - accuracy: 0.9197 - val_loss: 0.2820 - val_accuracy: 0.9214\n","Epoch 131/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2873 - accuracy: 0.9197 - val_loss: 0.2819 - val_accuracy: 0.9213\n","Epoch 132/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2871 - accuracy: 0.9197 - val_loss: 0.2817 - val_accuracy: 0.9218\n","Epoch 133/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2869 - accuracy: 0.9201 - val_loss: 0.2816 - val_accuracy: 0.9215\n","Epoch 134/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2867 - accuracy: 0.9198 - val_loss: 0.2815 - val_accuracy: 0.9218\n","Epoch 135/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2865 - accuracy: 0.9200 - val_loss: 0.2813 - val_accuracy: 0.9216\n","Epoch 136/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2863 - accuracy: 0.9201 - val_loss: 0.2812 - val_accuracy: 0.9217\n","Epoch 137/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2861 - accuracy: 0.9201 - val_loss: 0.2810 - val_accuracy: 0.9216\n","Epoch 138/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2859 - accuracy: 0.9202 - val_loss: 0.2810 - val_accuracy: 0.9213\n","Epoch 139/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2857 - accuracy: 0.9200 - val_loss: 0.2807 - val_accuracy: 0.9217\n","Epoch 140/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2855 - accuracy: 0.9199 - val_loss: 0.2807 - val_accuracy: 0.9218\n","Epoch 141/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2853 - accuracy: 0.9201 - val_loss: 0.2806 - val_accuracy: 0.9217\n","Epoch 142/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2851 - accuracy: 0.9202 - val_loss: 0.2805 - val_accuracy: 0.9216\n","Epoch 143/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2849 - accuracy: 0.9203 - val_loss: 0.2803 - val_accuracy: 0.9218\n","Epoch 144/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2847 - accuracy: 0.9204 - val_loss: 0.2802 - val_accuracy: 0.9218\n","Epoch 145/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2845 - accuracy: 0.9204 - val_loss: 0.2800 - val_accuracy: 0.9215\n","Epoch 146/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2843 - accuracy: 0.9207 - val_loss: 0.2799 - val_accuracy: 0.9220\n","Epoch 147/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2842 - accuracy: 0.9205 - val_loss: 0.2798 - val_accuracy: 0.9223\n","Epoch 148/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2840 - accuracy: 0.9207 - val_loss: 0.2797 - val_accuracy: 0.9218\n","Epoch 149/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2838 - accuracy: 0.9208 - val_loss: 0.2796 - val_accuracy: 0.9218\n","Epoch 150/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2836 - accuracy: 0.9207 - val_loss: 0.2795 - val_accuracy: 0.9219\n","Epoch 151/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2834 - accuracy: 0.9210 - val_loss: 0.2794 - val_accuracy: 0.9220\n","Epoch 152/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2832 - accuracy: 0.9207 - val_loss: 0.2792 - val_accuracy: 0.9227\n","Epoch 153/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2831 - accuracy: 0.9211 - val_loss: 0.2791 - val_accuracy: 0.9224\n","Epoch 154/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2829 - accuracy: 0.9208 - val_loss: 0.2790 - val_accuracy: 0.9220\n","Epoch 155/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2827 - accuracy: 0.9211 - val_loss: 0.2789 - val_accuracy: 0.9222\n","Epoch 156/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2826 - accuracy: 0.9210 - val_loss: 0.2788 - val_accuracy: 0.9222\n","Epoch 157/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2824 - accuracy: 0.9210 - val_loss: 0.2787 - val_accuracy: 0.9222\n","Epoch 158/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2822 - accuracy: 0.9215 - val_loss: 0.2787 - val_accuracy: 0.9222\n","Epoch 159/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2821 - accuracy: 0.9211 - val_loss: 0.2785 - val_accuracy: 0.9223\n","Epoch 160/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2819 - accuracy: 0.9213 - val_loss: 0.2784 - val_accuracy: 0.9221\n","Epoch 161/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2817 - accuracy: 0.9212 - val_loss: 0.2783 - val_accuracy: 0.9222\n","Epoch 162/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2816 - accuracy: 0.9211 - val_loss: 0.2782 - val_accuracy: 0.9221\n","Epoch 163/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2814 - accuracy: 0.9212 - val_loss: 0.2782 - val_accuracy: 0.9221\n","Epoch 164/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2813 - accuracy: 0.9213 - val_loss: 0.2780 - val_accuracy: 0.9223\n","Epoch 165/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2811 - accuracy: 0.9214 - val_loss: 0.2779 - val_accuracy: 0.9221\n","Epoch 166/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2809 - accuracy: 0.9214 - val_loss: 0.2778 - val_accuracy: 0.9222\n","Epoch 167/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2808 - accuracy: 0.9214 - val_loss: 0.2777 - val_accuracy: 0.9223\n","Epoch 168/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2806 - accuracy: 0.9216 - val_loss: 0.2775 - val_accuracy: 0.9225\n","Epoch 169/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2805 - accuracy: 0.9218 - val_loss: 0.2775 - val_accuracy: 0.9222\n","Epoch 170/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2803 - accuracy: 0.9216 - val_loss: 0.2775 - val_accuracy: 0.9222\n","Epoch 171/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2802 - accuracy: 0.9216 - val_loss: 0.2774 - val_accuracy: 0.9220\n","Epoch 172/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2800 - accuracy: 0.9216 - val_loss: 0.2772 - val_accuracy: 0.9226\n","Epoch 173/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2799 - accuracy: 0.9220 - val_loss: 0.2772 - val_accuracy: 0.9222\n","Epoch 174/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2797 - accuracy: 0.9218 - val_loss: 0.2771 - val_accuracy: 0.9222\n","Epoch 175/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2796 - accuracy: 0.9220 - val_loss: 0.2770 - val_accuracy: 0.9219\n","Epoch 176/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2794 - accuracy: 0.9219 - val_loss: 0.2769 - val_accuracy: 0.9222\n","Epoch 177/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2793 - accuracy: 0.9218 - val_loss: 0.2768 - val_accuracy: 0.9220\n","Epoch 178/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2792 - accuracy: 0.9221 - val_loss: 0.2767 - val_accuracy: 0.9227\n","Epoch 179/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2790 - accuracy: 0.9220 - val_loss: 0.2766 - val_accuracy: 0.9227\n","Epoch 180/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2788 - accuracy: 0.9223 - val_loss: 0.2767 - val_accuracy: 0.9224\n","Epoch 181/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2787 - accuracy: 0.9219 - val_loss: 0.2765 - val_accuracy: 0.9230\n","Epoch 182/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2786 - accuracy: 0.9221 - val_loss: 0.2764 - val_accuracy: 0.9218\n","Epoch 183/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2784 - accuracy: 0.9223 - val_loss: 0.2763 - val_accuracy: 0.9226\n","Epoch 184/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2783 - accuracy: 0.9222 - val_loss: 0.2763 - val_accuracy: 0.9223\n","Epoch 185/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2782 - accuracy: 0.9221 - val_loss: 0.2762 - val_accuracy: 0.9224\n","Epoch 186/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2780 - accuracy: 0.9226 - val_loss: 0.2760 - val_accuracy: 0.9225\n","Epoch 187/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2779 - accuracy: 0.9223 - val_loss: 0.2760 - val_accuracy: 0.9226\n","Epoch 188/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2778 - accuracy: 0.9222 - val_loss: 0.2759 - val_accuracy: 0.9227\n","Epoch 189/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2776 - accuracy: 0.9227 - val_loss: 0.2758 - val_accuracy: 0.9227\n","Epoch 190/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2775 - accuracy: 0.9227 - val_loss: 0.2757 - val_accuracy: 0.9227\n","Epoch 191/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2774 - accuracy: 0.9226 - val_loss: 0.2757 - val_accuracy: 0.9226\n","Epoch 192/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2772 - accuracy: 0.9226 - val_loss: 0.2757 - val_accuracy: 0.9227\n","Epoch 193/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2771 - accuracy: 0.9228 - val_loss: 0.2756 - val_accuracy: 0.9227\n","Epoch 194/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2770 - accuracy: 0.9226 - val_loss: 0.2755 - val_accuracy: 0.9228\n","Epoch 195/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2769 - accuracy: 0.9226 - val_loss: 0.2754 - val_accuracy: 0.9224\n","Epoch 196/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2767 - accuracy: 0.9226 - val_loss: 0.2753 - val_accuracy: 0.9231\n","Epoch 197/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2766 - accuracy: 0.9228 - val_loss: 0.2753 - val_accuracy: 0.9230\n","Epoch 198/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2765 - accuracy: 0.9229 - val_loss: 0.2752 - val_accuracy: 0.9229\n","Epoch 199/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2764 - accuracy: 0.9226 - val_loss: 0.2751 - val_accuracy: 0.9232\n","Epoch 200/200\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2763 - accuracy: 0.9230 - val_loss: 0.2751 - val_accuracy: 0.9227\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7feab0046550>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"YehY8OO_Fuf5","executionInfo":{"status":"ok","timestamp":1604642077209,"user_tz":0,"elapsed":238881,"user":{"displayName":"A J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZDwFqnFt3HwqF4Wu3Au0RSvls62YjJWudcDUj=s64","userId":"15417262701029927930"}},"outputId":"e74a999d-d219-49d7-8460-47f4e6aec525","colab":{"base_uri":"https://localhost:8080/"}},"source":["#evaluate the model\n","test_loss, test_acc = model.evaluate(X_test, Y_test)\n","print('Test accuracy:', test_acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["313/313 [==============================] - 1s 2ms/step - loss: 0.2772 - accuracy: 0.9224\n","Test accuracy: 0.9223999977111816\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xdZIoFLeFuf_"},"source":["# making prediction\n","predictions = model.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LrsZJWksptCX"},"source":["**Observations**\n","\n","We have achieved training accuracy 90.4,validation accuracy-91.1 and test accuracy - 92.24 with single dense laye and 200 epochs"]}]}
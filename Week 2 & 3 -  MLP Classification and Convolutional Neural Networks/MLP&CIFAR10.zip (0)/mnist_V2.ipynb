{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"mnist_V2.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"i6yFp91jkl1N"},"source":["### INTRODUCTION - This is an extension of previous mnist_v1 model for image classification with neural networks. So far we have understood the basic concepts of data loading, neural network model building, metric evaluation and prediction. From here, we will study different techniques for model tuning and refining. \n","### This is a sequential model with single input, single hidden and an output layer which introduces the concept of making model deeper (helps combat various complexities in data). It differs in epochs which is reduced to 50 from 200."]},{"cell_type":"code","metadata":{"id":"8RVCgwq0kl1T"},"source":["import tensorflow as tf\n","import numpy as np\n","from tensorflow import keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3U_rpXhkl10"},"source":["# network and training\n","EPOCHS = 50\n","BATCH_SIZE = 128\n","VERBOSE = 1\n","NB_CLASSES = 10   # number of outputs = number of digits\n","N_HIDDEN = 128\n","VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RbThuN7Ukl2F"},"source":["# loading MNIST dataset\n","# verify\n","# the split between train and test is 60,000, and 10,000 respectly \n","# one-hot is automatically applied\n","mnist = keras.datasets.mnist\n","(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A20xEdT5kl2U"},"source":["#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n","RESHAPED = 784\n","\n","X_train = X_train.reshape(60000, RESHAPED)\n","X_test = X_test.reshape(10000, RESHAPED)\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1SiHKhPTkl2h","executionInfo":{"status":"ok","timestamp":1604734614784,"user_tz":0,"elapsed":2121,"user":{"displayName":"A J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZDwFqnFt3HwqF4Wu3Au0RSvls62YjJWudcDUj=s64","userId":"15417262701029927930"}},"outputId":"6931582d-204d-4924-f13b-f91e9970df51","colab":{"base_uri":"https://localhost:8080/"}},"source":["#normalize in [0,1]\n","X_train, X_test = X_train / 255.0, X_test / 255.0\n","print(X_train.shape[0], 'train samples')\n","print(X_test.shape[0], 'test samples')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["60000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JhnxW_sqkl23"},"source":["#one-hot\n","Y_train = tf.keras.utils.to_categorical(Y_train, NB_CLASSES)\n","Y_test = tf.keras.utils.to_categorical(Y_test, NB_CLASSES)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"leFG88SHkl3C"},"source":["#build the model\n","model = tf.keras.models.Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0Th4Itwpkl3N"},"source":["model.add(keras.layers.Dense(N_HIDDEN,\n","    input_shape=(RESHAPED,),\n","    name='dense_layer', activation='relu'))\n","\n","'''This adds hidden layer to the neural network with activation function to be ‘relu’ (rectified linear unit). \n","Activation function is used to determine the output of neural network like yes or no. It maps the resulting values \n","in between 0 to 1 or -1 to 1 etc. (depending upon the function). \n","Reference to different activation functions - https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6\n","'''\n","model.add(keras.layers.Dense(N_HIDDEN,\n","    name='dense_layer_2', activation='relu'))\n","model.add(keras.layers.Dense(NB_CLASSES,\n","    name='dense_layer_3', activation='softmax'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fltBMtkfkl3W","executionInfo":{"status":"ok","timestamp":1604734615556,"user_tz":0,"elapsed":2876,"user":{"displayName":"A J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZDwFqnFt3HwqF4Wu3Au0RSvls62YjJWudcDUj=s64","userId":"15417262701029927930"}},"outputId":"04d69daf-0050-498a-eb0d-86808e115afb","colab":{"base_uri":"https://localhost:8080/"}},"source":["# summary of the model\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_layer (Dense)          (None, 128)               100480    \n","_________________________________________________________________\n","dense_layer_2 (Dense)        (None, 128)               16512     \n","_________________________________________________________________\n","dense_layer_3 (Dense)        (None, 10)                1290      \n","=================================================================\n","Total params: 118,282\n","Trainable params: 118,282\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7FNbpEsxkl3e"},"source":["# compiling the model\n","model.compile(optimizer='SGD', \n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rPaU4nO4kl3n","executionInfo":{"status":"ok","timestamp":1604734664052,"user_tz":0,"elapsed":51361,"user":{"displayName":"A J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZDwFqnFt3HwqF4Wu3Au0RSvls62YjJWudcDUj=s64","userId":"15417262701029927930"}},"outputId":"a4d0dfc1-7ae7-46e9-9149-76ddcb27bf54","colab":{"base_uri":"https://localhost:8080/"}},"source":["#training the model\n","model.fit(X_train, Y_train,\n","        batch_size=BATCH_SIZE, epochs=EPOCHS,\n","        verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","375/375 [==============================] - 1s 3ms/step - loss: 1.4400 - accuracy: 0.6519 - val_loss: 0.7312 - val_accuracy: 0.8371\n","Epoch 2/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.5919 - accuracy: 0.8506 - val_loss: 0.4576 - val_accuracy: 0.8789\n","Epoch 3/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.4407 - accuracy: 0.8797 - val_loss: 0.3790 - val_accuracy: 0.8962\n","Epoch 4/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.3806 - accuracy: 0.8940 - val_loss: 0.3398 - val_accuracy: 0.9051\n","Epoch 5/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.3459 - accuracy: 0.9014 - val_loss: 0.3140 - val_accuracy: 0.9119\n","Epoch 6/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.3220 - accuracy: 0.9092 - val_loss: 0.2955 - val_accuracy: 0.9155\n","Epoch 7/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.3037 - accuracy: 0.9136 - val_loss: 0.2806 - val_accuracy: 0.9205\n","Epoch 8/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2887 - accuracy: 0.9176 - val_loss: 0.2676 - val_accuracy: 0.9237\n","Epoch 9/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2758 - accuracy: 0.9205 - val_loss: 0.2579 - val_accuracy: 0.9261\n","Epoch 10/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2645 - accuracy: 0.9247 - val_loss: 0.2478 - val_accuracy: 0.9290\n","Epoch 11/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2542 - accuracy: 0.9273 - val_loss: 0.2389 - val_accuracy: 0.9313\n","Epoch 12/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2446 - accuracy: 0.9303 - val_loss: 0.2314 - val_accuracy: 0.9333\n","Epoch 13/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2364 - accuracy: 0.9319 - val_loss: 0.2242 - val_accuracy: 0.9362\n","Epoch 14/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.2281 - accuracy: 0.9353 - val_loss: 0.2179 - val_accuracy: 0.9394\n","Epoch 15/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2210 - accuracy: 0.9372 - val_loss: 0.2130 - val_accuracy: 0.9398\n","Epoch 16/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2141 - accuracy: 0.9388 - val_loss: 0.2065 - val_accuracy: 0.9419\n","Epoch 17/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2077 - accuracy: 0.9405 - val_loss: 0.2018 - val_accuracy: 0.9433\n","Epoch 18/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.2017 - accuracy: 0.9419 - val_loss: 0.1959 - val_accuracy: 0.9457\n","Epoch 19/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1959 - accuracy: 0.9441 - val_loss: 0.1923 - val_accuracy: 0.9464\n","Epoch 20/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1905 - accuracy: 0.9458 - val_loss: 0.1881 - val_accuracy: 0.9483\n","Epoch 21/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1852 - accuracy: 0.9467 - val_loss: 0.1843 - val_accuracy: 0.9490\n","Epoch 22/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1805 - accuracy: 0.9483 - val_loss: 0.1798 - val_accuracy: 0.9503\n","Epoch 23/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1758 - accuracy: 0.9496 - val_loss: 0.1767 - val_accuracy: 0.9500\n","Epoch 24/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1715 - accuracy: 0.9508 - val_loss: 0.1734 - val_accuracy: 0.9521\n","Epoch 25/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1673 - accuracy: 0.9519 - val_loss: 0.1697 - val_accuracy: 0.9523\n","Epoch 26/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1633 - accuracy: 0.9538 - val_loss: 0.1680 - val_accuracy: 0.9528\n","Epoch 27/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1595 - accuracy: 0.9550 - val_loss: 0.1637 - val_accuracy: 0.9533\n","Epoch 28/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1558 - accuracy: 0.9558 - val_loss: 0.1611 - val_accuracy: 0.9542\n","Epoch 29/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1523 - accuracy: 0.9569 - val_loss: 0.1593 - val_accuracy: 0.9560\n","Epoch 30/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1491 - accuracy: 0.9580 - val_loss: 0.1562 - val_accuracy: 0.9566\n","Epoch 31/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1458 - accuracy: 0.9589 - val_loss: 0.1558 - val_accuracy: 0.9556\n","Epoch 32/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1428 - accuracy: 0.9599 - val_loss: 0.1515 - val_accuracy: 0.9580\n","Epoch 33/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1398 - accuracy: 0.9606 - val_loss: 0.1506 - val_accuracy: 0.9583\n","Epoch 34/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1369 - accuracy: 0.9618 - val_loss: 0.1479 - val_accuracy: 0.9586\n","Epoch 35/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1344 - accuracy: 0.9620 - val_loss: 0.1458 - val_accuracy: 0.9594\n","Epoch 36/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1317 - accuracy: 0.9634 - val_loss: 0.1440 - val_accuracy: 0.9603\n","Epoch 37/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1293 - accuracy: 0.9637 - val_loss: 0.1414 - val_accuracy: 0.9603\n","Epoch 38/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1266 - accuracy: 0.9647 - val_loss: 0.1408 - val_accuracy: 0.9607\n","Epoch 39/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1245 - accuracy: 0.9650 - val_loss: 0.1384 - val_accuracy: 0.9618\n","Epoch 40/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1221 - accuracy: 0.9655 - val_loss: 0.1372 - val_accuracy: 0.9614\n","Epoch 41/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1200 - accuracy: 0.9664 - val_loss: 0.1353 - val_accuracy: 0.9627\n","Epoch 42/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1177 - accuracy: 0.9671 - val_loss: 0.1334 - val_accuracy: 0.9627\n","Epoch 43/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1157 - accuracy: 0.9673 - val_loss: 0.1322 - val_accuracy: 0.9642\n","Epoch 44/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1136 - accuracy: 0.9686 - val_loss: 0.1312 - val_accuracy: 0.9638\n","Epoch 45/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1117 - accuracy: 0.9687 - val_loss: 0.1305 - val_accuracy: 0.9638\n","Epoch 46/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1098 - accuracy: 0.9691 - val_loss: 0.1289 - val_accuracy: 0.9643\n","Epoch 47/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1082 - accuracy: 0.9693 - val_loss: 0.1281 - val_accuracy: 0.9643\n","Epoch 48/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1062 - accuracy: 0.9700 - val_loss: 0.1260 - val_accuracy: 0.9654\n","Epoch 49/50\n","375/375 [==============================] - 1s 2ms/step - loss: 0.1046 - accuracy: 0.9706 - val_loss: 0.1252 - val_accuracy: 0.9658\n","Epoch 50/50\n","375/375 [==============================] - 1s 3ms/step - loss: 0.1028 - accuracy: 0.9709 - val_loss: 0.1239 - val_accuracy: 0.9663\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f8e280a7518>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"S40ZNjlXkl3v","executionInfo":{"status":"ok","timestamp":1604734664612,"user_tz":0,"elapsed":51916,"user":{"displayName":"A J","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZDwFqnFt3HwqF4Wu3Au0RSvls62YjJWudcDUj=s64","userId":"15417262701029927930"}},"outputId":"e7402877-4ad6-467a-ca85-b8cc75d0d283","colab":{"base_uri":"https://localhost:8080/"}},"source":["#evaluate the model\n","test_loss, test_acc = model.evaluate(X_test, Y_test)\n","print('Test accuracy:', test_acc)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["313/313 [==============================] - 1s 2ms/step - loss: 0.1198 - accuracy: 0.9642\n","Test accuracy: 0.9642000198364258\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"re9VkwPYkl34"},"source":["# making prediction\n","predictions = model.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9nJJnSdaoomf"},"source":["**Observations**\n","\n","We have achieved improved accuracy with additional hidden layers even though the epochs have been reduced to 50. training accuracy 97.09,validation accuracy-96.63 and test accuracy - 96.42"]}]}